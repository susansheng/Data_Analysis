#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åˆ†æå·¥å…· - ç”¨æˆ·è¡Œä¸ºæ¼æ–—åˆ†æ
åŸºäºæ›å…‰->ç‚¹å‡»->è½¬åŒ–->ä¸‹å•çš„ç”¨æˆ·è¡Œä¸ºæ¼æ–—ï¼Œç²¾å‡†è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡å¹¶è¾“å‡ºä¸šåŠ¡æ´å¯Ÿ
"""

import pandas as pd
import numpy as np
import argparse
import sys
from pathlib import Path
from datetime import datetime


class FunnelAnalyzer:
    """æ¼æ–—åˆ†ææ ¸å¿ƒç±»"""

    def __init__(self, file_path, min_click_threshold=10):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            min_click_threshold: æœ€å°ç‚¹å‡»é‡é˜ˆå€¼ï¼Œç”¨äºè¿‡æ»¤é•¿å°¾å™ªéŸ³
        """
        self.file_path = file_path
        self.min_click_threshold = min_click_threshold
        self.df = None
        self.report = []

    def load_data(self):
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        try:
            if self.file_path.endswith('.xlsx') or self.file_path.endswith('.xls'):
                self.df = pd.read_excel(self.file_path)
            elif self.file_path.endswith('.csv'):
                self.df = pd.read_csv(self.file_path)
            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨ .xlsx, .xls æˆ– .csv æ–‡ä»¶")

            print(f"âœ“ æˆåŠŸåŠ è½½æ•°æ®: {len(self.df)} è¡Œ Ã— {len(self.df.columns)} åˆ—")
            return True
        except Exception as e:
            print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            return False

    def audit_and_clean(self):
        """æ­¥éª¤1: æ•°æ®å®¡è®¡ä¸æ¸…æ´—"""
        print("\n" + "="*80)
        print("æ­¥éª¤1: æ•°æ®å®¡è®¡ä¸æ¸…æ´—")
        print("="*80)

        # å­—æ®µæ˜ å°„è¯†åˆ«
        print("\nğŸ“‹ å­—æ®µæ˜ å°„è¯†åˆ«:")
        field_mapping = {
            'æ›å…‰äººæ•°': 'é¡µé¢UV(SUM)',
            'ç‚¹å‡»äººæ•°': 'ç‚¹å‡»UV(SUM)',
            'è½¬åŒ–äººæ•°ï¼ˆæäº¤å•ï¼‰': 'ç‚¹å‡»ç”¨æˆ·æäº¤å•(SUM)',
            'ä¸‹å•äººæ•°ï¼ˆé¢„è®¢å•ï¼‰': 'ç‚¹å‡»ç”¨æˆ·é¢„è®¢å•(SUM)'
        }

        for label, col in field_mapping.items():
            if col in self.df.columns:
                print(f"  âœ“ {label}: {col}")
            else:
                print(f"  âœ— {label}: å­—æ®µç¼ºå¤±")

        # æ•°æ®æ¸…æ´—å‰çš„ç»Ÿè®¡
        original_count = len(self.df)
        print(f"\nğŸ“Š åŸå§‹æ•°æ®: {original_count} æ¡è®°å½•")

        # 1. å‰”é™¤ç‚¹å‡»é‡ < é˜ˆå€¼çš„é•¿å°¾æ•°æ®
        self.df = self.df[self.df['ç‚¹å‡»UV(SUM)'] >= self.min_click_threshold]
        after_click_filter = len(self.df)
        print(f"  âœ“ å‰”é™¤ç‚¹å‡»é‡ < {self.min_click_threshold} çš„æ•°æ®: {original_count - after_click_filter} æ¡")

        # 2. å‰”é™¤å¼‚å¸¸æ•°æ®ï¼ˆç‚¹å‡» > æ›å…‰ï¼‰
        self.df = self.df[self.df['ç‚¹å‡»UV(SUM)'] <= self.df['é¡µé¢UV(SUM)']]
        after_anomaly_filter = len(self.df)
        print(f"  âœ“ å‰”é™¤ç‚¹å‡» > æ›å…‰çš„å¼‚å¸¸æ•°æ®: {after_click_filter - after_anomaly_filter} æ¡")

        # 3. æ£€æŸ¥ç¼ºå¤±å€¼
        null_counts = self.df.isnull().sum()
        if null_counts.sum() > 0:
            print(f"\nâš ï¸  å‘ç°ç¼ºå¤±å€¼:")
            for col, count in null_counts[null_counts > 0].items():
                print(f"    {col}: {count} ä¸ªç¼ºå¤±å€¼")
        else:
            print(f"\nâœ“ æ— ç¼ºå¤±å€¼")

        print(f"\nâœ“ æ¸…æ´—åæ•°æ®: {len(self.df)} æ¡è®°å½•")

    def calculate_metrics(self, group_df):
        """
        è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡

        Args:
            group_df: åˆ†ç»„æ•°æ®æ¡†

        Returns:
            dict: åŒ…å«å„é¡¹æŒ‡æ ‡çš„å­—å…¸
        """
        total_exposure = group_df['é¡µé¢UV(SUM)'].sum()
        total_click = group_df['ç‚¹å‡»UV(SUM)'].sum()
        total_convert = group_df['ç‚¹å‡»ç”¨æˆ·æäº¤å•(SUM)'].sum()
        total_order = group_df['ç‚¹å‡»ç”¨æˆ·é¢„è®¢å•(SUM)'].sum()

        # é¿å…é™¤é›¶é”™è¯¯
        ctr = (total_click / total_exposure * 100) if total_exposure > 0 else 0
        click_cvr = (total_convert / total_click * 100) if total_click > 0 else 0
        order_cvr = (total_order / total_click * 100) if total_click > 0 else 0

        return {
            'exposure': total_exposure,
            'click': total_click,
            'convert': total_convert,
            'order': total_order,
            'ctr': round(ctr, 2),
            'click_cvr': round(click_cvr, 2),
            'order_cvr': round(order_cvr, 2)
        }

    def multi_dimensional_analysis(self):
        """æ­¥éª¤2: å¤šç»´äº¤å‰åˆ†æ"""
        print("\n" + "="*80)
        print("æ­¥éª¤2: å¤šç»´äº¤å‰åˆ†æ")
        print("="*80)

        # 1. æ•´ä½“æ¼æ–—è®¡ç®—
        print("\nğŸ“Š æ•´ä½“æŒ‡æ ‡è®¡ç®—:")
        overall_metrics = self.calculate_metrics(self.df)

        print(f"  æ›å…‰äººæ•°: {overall_metrics['exposure']:,}")
        print(f"  ç‚¹å‡»äººæ•°: {overall_metrics['click']:,}")
        print(f"  è½¬åŒ–äººæ•°: {overall_metrics['convert']:,}")
        print(f"  ä¸‹å•äººæ•°: {overall_metrics['order']:,}")
        print(f"  âœ“ ç‚¹å‡»ç‡ (CTR): {overall_metrics['ctr']}%")
        print(f"  âœ“ ç‚¹å‡»è½¬åŒ–ç‡ (Click CVR): {overall_metrics['click_cvr']}%")
        print(f"  âœ“ ä¸‹å•è½¬åŒ–ç‡ (Order CVR): {overall_metrics['order_cvr']}%")

        self.overall_metrics = overall_metrics

        # 2. æŒ‰ç‚¹å‡»äº‹ä»¶åˆ†æï¼ˆæ¨¡å—çº§åˆ†æï¼‰
        print("\nğŸ“Š æŒ‰ç‚¹å‡»äº‹ä»¶åˆ†ç»„åˆ†æ:")
        event_analysis = self.df.groupby('ç‚¹å‡»äº‹ä»¶åç§°').apply(
            lambda x: pd.Series({
                'æ›å…‰äººæ•°': x['é¡µé¢UV(SUM)'].sum(),
                'ç‚¹å‡»äººæ•°': x['ç‚¹å‡»UV(SUM)'].sum(),
                'è½¬åŒ–äººæ•°': x['ç‚¹å‡»ç”¨æˆ·æäº¤å•(SUM)'].sum(),
                'ä¸‹å•äººæ•°': x['ç‚¹å‡»ç”¨æˆ·é¢„è®¢å•(SUM)'].sum(),
            })
        ).reset_index()

        # è®¡ç®—æŒ‡æ ‡
        event_analysis['ç‚¹å‡»ç‡(CTR)'] = (
            event_analysis['ç‚¹å‡»äººæ•°'] / event_analysis['æ›å…‰äººæ•°'] * 100
        ).round(2)
        event_analysis['ç‚¹å‡»è½¬åŒ–ç‡'] = (
            event_analysis['è½¬åŒ–äººæ•°'] / event_analysis['ç‚¹å‡»äººæ•°'] * 100
        ).round(2)
        event_analysis['ä¸‹å•è½¬åŒ–ç‡'] = (
            event_analysis['ä¸‹å•äººæ•°'] / event_analysis['ç‚¹å‡»äººæ•°'] * 100
        ).round(2)

        # æŒ‰ç‚¹å‡»ç‡é™åºæ’åˆ—
        event_analysis = event_analysis.sort_values('ç‚¹å‡»ç‡(CTR)', ascending=False)

        self.event_analysis = event_analysis
        print(f"  âœ“ è¯†åˆ«åˆ° {len(event_analysis)} ä¸ªä¸åŒçš„ç‚¹å‡»äº‹ä»¶")

        # 3. æŒ‰å¹³å°åˆ†æ
        if 'å¹³å°' in self.df.columns:
            print("\nğŸ“Š æŒ‰å¹³å°åˆ†ç»„åˆ†æ:")
            platform_analysis = self.df.groupby('å¹³å°').apply(
                lambda x: pd.Series(self.calculate_metrics(x))
            )
            print(platform_analysis[['ctr', 'click_cvr', 'order_cvr']])
            self.platform_analysis = platform_analysis

        # 4. æŒ‰æ—¥æœŸè¶‹åŠ¿åˆ†æ
        if 'æ—¥æœŸ' in self.df.columns:
            print("\nğŸ“Š æŒ‰æ—¥æœŸè¶‹åŠ¿åˆ†æ:")
            self.df['æ—¥æœŸ'] = pd.to_datetime(self.df['æ—¥æœŸ'])
            date_analysis = self.df.groupby('æ—¥æœŸ').apply(
                lambda x: pd.Series(self.calculate_metrics(x))
            )
            self.date_analysis = date_analysis
            print(f"  âœ“ æ—¶é—´è·¨åº¦: {self.df['æ—¥æœŸ'].min()} è‡³ {self.df['æ—¥æœŸ'].max()}")
            print(f"  âœ“ å…± {len(date_analysis)} å¤©æ•°æ®")

    def generate_top_list(self, top_n=50):
        """ç”ŸæˆTop Né«˜ç‚¹å‡»ç‡æ¨¡å—æ¦œå•"""
        print(f"\nğŸ† ç”Ÿæˆ Top {top_n} é«˜ç‚¹å‡»ç‡æ¨¡å—æ¦œå•")

        # è·å–å‰Næ¡è®°å½•
        self.top_modules = self.event_analysis.head(top_n).copy()

        # æ·»åŠ æ’å
        self.top_modules.insert(0, 'æ’å', range(1, len(self.top_modules) + 1))

        print(f"  âœ“ å·²ç”Ÿæˆ Top {len(self.top_modules)} æ¦œå•")

        return self.top_modules

    def generate_visualizations(self):
        """æ­¥éª¤3: ç”Ÿæˆæ•°æ®å¯è§†åŒ–ä»£ç ï¼ˆMermaidï¼‰"""
        print("\n" + "="*80)
        print("æ­¥éª¤3: æ•°æ®å¯è§†åŒ–")
        print("="*80)

        visualizations = []

        # 1. æ¼æ–—è½¬åŒ–è¶‹åŠ¿å›¾
        if hasattr(self, 'date_analysis') and len(self.date_analysis) > 0:
            # å–æœ€è¿‘10å¤©çš„æ•°æ®
            recent_dates = self.date_analysis.tail(10)

            mermaid_line = "```mermaid\n"
            mermaid_line += "%%{init: {'theme':'base'}}%%\n"
            mermaid_line += "xychart-beta\n"
            mermaid_line += "    title \"æ ¸å¿ƒæŒ‡æ ‡è¶‹åŠ¿ (æœ€è¿‘10å¤©)\"\n"
            mermaid_line += "    x-axis [" + ", ".join([f'"{d.strftime("%m-%d")}"' for d in recent_dates.index]) + "]\n"
            mermaid_line += "    y-axis \"è½¬åŒ–ç‡ (%)\" 0 --> 100\n"
            mermaid_line += "    line [" + ", ".join([str(v) for v in recent_dates['ctr'].values]) + "]\n"
            mermaid_line += "    line [" + ", ".join([str(v) for v in recent_dates['click_cvr'].values]) + "]\n"
            mermaid_line += "    line [" + ", ".join([str(v) for v in recent_dates['order_cvr'].values]) + "]\n"
            mermaid_line += "```\n"

            visualizations.append(("æ¼æ–—è¶‹åŠ¿å›¾", mermaid_line))

        # 2. Top 10æ¨¡å—ç‚¹å‡»ç‡å¯¹æ¯”
        if hasattr(self, 'top_modules'):
            top10 = self.top_modules.head(10)

            mermaid_bar = "```mermaid\n"
            mermaid_bar += "%%{init: {'theme':'base'}}%%\n"
            mermaid_bar += "xychart-beta\n"
            mermaid_bar += "    title \"Top 10 æ¨¡å—ç‚¹å‡»ç‡å¯¹æ¯”\"\n"

            # ç®€åŒ–æ¨¡å—åç§°ï¼ˆå–å‰10ä¸ªå­—ç¬¦ï¼‰
            labels = [name[:10] + "..." if len(name) > 10 else name for name in top10['ç‚¹å‡»äº‹ä»¶åç§°'].values]
            mermaid_bar += "    x-axis [" + ", ".join([f'"{label}"' for label in labels]) + "]\n"
            mermaid_bar += "    y-axis \"ç‚¹å‡»ç‡ (%)\" 0 --> 100\n"
            mermaid_bar += "    bar [" + ", ".join([str(v) for v in top10['ç‚¹å‡»ç‡(CTR)'].values]) + "]\n"
            mermaid_bar += "```\n"

            visualizations.append(("Top 10æ¨¡å—ç‚¹å‡»ç‡", mermaid_bar))

        self.visualizations = visualizations
        print(f"  âœ“ ç”Ÿæˆ {len(visualizations)} ä¸ªå¯è§†åŒ–å›¾è¡¨")

    def generate_insights(self):
        """æ­¥éª¤4: å½’å› ä¸å»ºè®®"""
        print("\n" + "="*80)
        print("æ­¥éª¤4: å½’å› ä¸ä¸šåŠ¡å»ºè®®")
        print("="*80)

        insights = []

        # 1. æ¼æ–—æµå¤±åˆ†æ
        ctr = self.overall_metrics['ctr']
        click_cvr = self.overall_metrics['click_cvr']
        order_cvr = self.overall_metrics['order_cvr']

        # æ‰¾å‡ºæœ€å¤§æµå¤±ç¯èŠ‚
        click_loss = 100 - ctr
        convert_loss = 100 - click_cvr
        order_loss = 100 - order_cvr

        max_loss_stage = max(
            ('æ›å…‰åˆ°ç‚¹å‡»', click_loss),
            ('ç‚¹å‡»åˆ°è½¬åŒ–', convert_loss),
            ('è½¬åŒ–åˆ°ä¸‹å•', order_loss),
            key=lambda x: x[1]
        )

        insights.append({
            'title': 'ğŸ” æ¼æ–—æµå¤±åˆ†æ',
            'content': [
                f"æœ€å¤§æµå¤±ç¯èŠ‚: **{max_loss_stage[0]}**ï¼Œæµå¤±ç‡ {max_loss_stage[1]:.2f}%",
                f"- æ›å…‰åˆ°ç‚¹å‡»: {click_loss:.2f}% ç”¨æˆ·æœªç‚¹å‡»",
                f"- ç‚¹å‡»åˆ°è½¬åŒ–: {convert_loss:.2f}% ç”¨æˆ·ç‚¹å‡»åæœªæäº¤è®¢å•",
                f"- è½¬åŒ–åˆ°ä¸‹å•: {order_loss:.2f}% ç”¨æˆ·æäº¤åæœªå®Œæˆé¢„è®¢"
            ]
        })

        # 2. é«˜ä»·å€¼æ¨¡å—è¯†åˆ«
        if hasattr(self, 'top_modules'):
            top5 = self.top_modules.head(5)
            insights.append({
                'title': 'ğŸ† é«˜ä»·å€¼æ¨¡å—æ¨è',
                'content': [
                    "ä»¥ä¸‹æ¨¡å—ç‚¹å‡»ç‡æœ€é«˜ï¼Œå»ºè®®é‡ç‚¹æ¨å¹¿:",
                    *[f"- **{row['ç‚¹å‡»äº‹ä»¶åç§°']}**: CTR {row['ç‚¹å‡»ç‡(CTR)']}%, ä¸‹å•CVR {row['ä¸‹å•è½¬åŒ–ç‡']}%"
                      for _, row in top5.iterrows()]
                ]
            })

        # 3. ä½æ•ˆæ¨¡å—é¢„è­¦
        if hasattr(self, 'event_analysis'):
            # æ‰¾å‡ºç‚¹å‡»ç‡ä½ä½†æ›å…‰é‡å¤§çš„æ¨¡å—
            low_ctr = self.event_analysis[
                (self.event_analysis['ç‚¹å‡»ç‡(CTR)'] < ctr * 0.5) &
                (self.event_analysis['æ›å…‰äººæ•°'] > self.event_analysis['æ›å…‰äººæ•°'].median())
            ].head(5)

            if len(low_ctr) > 0:
                insights.append({
                    'title': 'âš ï¸ ä½æ•ˆæ¨¡å—é¢„è­¦',
                    'content': [
                        "ä»¥ä¸‹æ¨¡å—æ›å…‰é‡å¤§ä½†ç‚¹å‡»ç‡ä½ï¼Œéœ€ä¼˜åŒ–:",
                        *[f"- **{row['ç‚¹å‡»äº‹ä»¶åç§°']}**: CTR {row['ç‚¹å‡»ç‡(CTR)']}% (æ›å…‰ {row['æ›å…‰äººæ•°']:,})"
                          for _, row in low_ctr.iterrows()]
                    ]
                })

        # 4. ä¼˜åŒ–å»ºè®®
        insights.append({
            'title': 'ğŸ’¡ ä¸šåŠ¡ä¼˜åŒ–å»ºè®®',
            'content': [
                f"**é’ˆå¯¹{max_loss_stage[0]}ç¯èŠ‚æµå¤±:**",
            ]
        })

        if max_loss_stage[0] == 'æ›å…‰åˆ°ç‚¹å‡»':
            insights[-1]['content'].extend([
                "- ä¼˜åŒ–æ¨¡å—è§†è§‰è®¾è®¡ï¼Œæå‡å¸å¼•åŠ›",
                "- è°ƒæ•´æ¨¡å—ä½ç½®ï¼Œå¢åŠ æ›å…‰è´¨é‡",
                "- A/Bæµ‹è¯•ä¸åŒçš„æ–‡æ¡ˆå’Œå›¾ç‰‡"
            ])
        elif max_loss_stage[0] == 'ç‚¹å‡»åˆ°è½¬åŒ–':
            insights[-1]['content'].extend([
                "- ä¼˜åŒ–å¡«å†™é¡µä½“éªŒï¼Œç®€åŒ–æµç¨‹",
                "- æ£€æŸ¥é¡µé¢åŠ è½½é€Ÿåº¦",
                "- å¢åŠ ä¿¡ä»»èƒŒä¹¦å’Œä¼˜æƒ æç¤º"
            ])
        else:
            insights[-1]['content'].extend([
                "- ä¼˜åŒ–æ”¯ä»˜æµç¨‹ï¼Œå‡å°‘æ”¯ä»˜æ‘©æ“¦",
                "- æ£€æŸ¥ä»·æ ¼ç­–ç•¥å’Œä¼˜æƒ åˆ¸ä½¿ç”¨",
                "- å¢åŠ è®¢å•ç¡®è®¤é¡µçš„ä¿¡æ¯é€æ˜åº¦"
            ])

        self.insights = insights
        print(f"  âœ“ ç”Ÿæˆ {len(insights)} æ¡ä¸šåŠ¡æ´å¯Ÿ")

    def generate_markdown_report(self, output_path=None):
        """ç”Ÿæˆå®Œæ•´çš„Markdownåˆ†ææŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ç”Ÿæˆåˆ†ææŠ¥å‘Š")
        print("="*80)

        if output_path is None:
            output_path = f"funnel_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

        report_lines = []

        # æ ‡é¢˜
        report_lines.append("# ğŸ“Š æ¨¡å—è½¬åŒ–æ•ˆèƒ½æ·±åº¦åˆ†ææŠ¥å‘Š\n")
        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report_lines.append(f"**æ•°æ®æ¥æº**: {Path(self.file_path).name}\n")
        report_lines.append(f"**åˆ†ææ•°æ®é‡**: {len(self.df):,} æ¡è®°å½•\n")
        report_lines.append("\n---\n\n")

        # 1. æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆ
        report_lines.append("## 1. ğŸ“‹ æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆ\n\n")
        report_lines.append("| æŒ‡æ ‡ | æ•°å€¼ |\n")
        report_lines.append("| :--- | :--- |\n")
        report_lines.append(f"| **æ•´ä½“ç‚¹å‡»ç‡ (CTR)** | **{self.overall_metrics['ctr']}%** |\n")
        report_lines.append(f"| **æ•´ä½“ç‚¹å‡»è½¬åŒ–ç‡ (Click CVR)** | **{self.overall_metrics['click_cvr']}%** |\n")
        report_lines.append(f"| **æ•´ä½“ä¸‹å•è½¬åŒ–ç‡ (Order CVR)** | **{self.overall_metrics['order_cvr']}%** |\n")
        report_lines.append(f"| æ€»æ›å…‰äººæ•° | {self.overall_metrics['exposure']:,} |\n")
        report_lines.append(f"| æ€»ç‚¹å‡»äººæ•° | {self.overall_metrics['click']:,} |\n")
        report_lines.append(f"| æ€»è½¬åŒ–äººæ•° | {self.overall_metrics['convert']:,} |\n")
        report_lines.append(f"| æ€»ä¸‹å•äººæ•° | {self.overall_metrics['order']:,} |\n")
        report_lines.append("\n")

        # 2. Top 50 é«˜ç‚¹å‡»ç‡æ¨¡å—æ¦œå•
        report_lines.append("## 2. ğŸ† Top 50 é«˜ç‚¹å‡»ç‡æ¨¡å—æ¦œå•\n\n")
        report_lines.append("æŒ‰ç‚¹å‡»ç‡é™åºæ’åˆ—ï¼Œå±•ç¤ºè¡¨ç°æœ€ä¼˜ç§€çš„æ¨¡å—:\n\n")

        # ç”Ÿæˆè¡¨æ ¼
        report_lines.append("| æ’å | æ¨¡å—åç§° | æ›å…‰äººæ•° | ç‚¹å‡»äººæ•° | **ç‚¹å‡»ç‡(CTR)** | ç‚¹å‡»è½¬åŒ–ç‡ | ä¸‹å•è½¬åŒ–ç‡ |\n")
        report_lines.append("| :---: | :--- | ---: | ---: | ---: | ---: | ---: |\n")

        for _, row in self.top_modules.iterrows():
            report_lines.append(
                f"| {row['æ’å']} "
                f"| {row['ç‚¹å‡»äº‹ä»¶åç§°']} "
                f"| {row['æ›å…‰äººæ•°']:,} "
                f"| {row['ç‚¹å‡»äººæ•°']:,} "
                f"| **{row['ç‚¹å‡»ç‡(CTR)']}%** "
                f"| {row['ç‚¹å‡»è½¬åŒ–ç‡']}% "
                f"| {row['ä¸‹å•è½¬åŒ–ç‡']}% |\n"
            )

        report_lines.append("\n")

        # 3. æ•°æ®å¯è§†åŒ–
        if hasattr(self, 'visualizations') and len(self.visualizations) > 0:
            report_lines.append("## 3. ğŸ“ˆ å¯è§†åŒ–çœ‹æ¿\n\n")

            for viz_title, viz_code in self.visualizations:
                report_lines.append(f"### {viz_title}\n\n")
                report_lines.append(viz_code)
                report_lines.append("\n")

        # 4. ä¸šåŠ¡æ´å¯Ÿä¸å»ºè®®
        if hasattr(self, 'insights'):
            report_lines.append("## 4. ğŸ’¡ ä¸šåŠ¡æ´å¯Ÿä¸ä¼˜åŒ–å»ºè®®\n\n")

            for insight in self.insights:
                report_lines.append(f"### {insight['title']}\n\n")
                for content in insight['content']:
                    report_lines.append(f"{content}\n")
                report_lines.append("\n")

        # 5. é™„å½•
        report_lines.append("## 5. ğŸ“ é™„å½•\n\n")
        report_lines.append("### æŒ‡æ ‡è®¡ç®—å…¬å¼\n\n")
        report_lines.append("1. **æ¨¡å—ç‚¹å‡»ç‡ (CTR)** = `(ç‚¹å‡»äººæ•° / æ›å…‰äººæ•°) Ã— 100%`\n")
        report_lines.append("2. **ç‚¹å‡»è½¬åŒ–ç‡ (Click CVR)** = `(è½¬åŒ–äººæ•° / ç‚¹å‡»äººæ•°) Ã— 100%`\n")
        report_lines.append("3. **ä¸‹å•è½¬åŒ–ç‡ (Order CVR)** = `(ä¸‹å•äººæ•° / ç‚¹å‡»äººæ•°) Ã— 100%`\n\n")

        report_lines.append("### æ•°æ®æ¸…æ´—è§„åˆ™\n\n")
        report_lines.append(f"- å‰”é™¤ç‚¹å‡»é‡ < {self.min_click_threshold} çš„é•¿å°¾æ•°æ®\n")
        report_lines.append("- å‰”é™¤ç‚¹å‡» > æ›å…‰çš„å¼‚å¸¸æ•°æ®\n")
        report_lines.append("- æ‰€æœ‰æŒ‡æ ‡ä¿ç•™2ä½å°æ•°\n\n")

        report_lines.append("---\n\n")
        report_lines.append("*ğŸ¤– æœ¬æŠ¥å‘Šç”±æ•°æ®åˆ†æå·¥å…·è‡ªåŠ¨ç”Ÿæˆ*\n")

        # å†™å…¥æ–‡ä»¶
        report_content = "".join(report_lines)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        print(f"\nâœ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path

    def run_analysis(self, output_path=None):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹æ•°æ®åˆ†æ")
        print("="*80)

        # åŠ è½½æ•°æ®
        if not self.load_data():
            return False

        # æ‰§è¡Œåˆ†ææ­¥éª¤
        self.audit_and_clean()
        self.multi_dimensional_analysis()
        self.generate_top_list()
        self.generate_visualizations()
        self.generate_insights()
        report_path = self.generate_markdown_report(output_path)

        print("\n" + "="*80)
        print("âœ… åˆ†æå®Œæˆ!")
        print("="*80)
        print(f"\nğŸ“„ æŠ¥å‘Šä½ç½®: {report_path}")

        return True


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description='æ•°æ®åˆ†æå·¥å…· - ç”¨æˆ·è¡Œä¸ºæ¼æ–—åˆ†æ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python funnel_analyzer.py data.xlsx
  python funnel_analyzer.py data.xlsx -o report.md
  python funnel_analyzer.py data.xlsx --min-click 20
        """
    )

    parser.add_argument('file', help='æ•°æ®æ–‡ä»¶è·¯å¾„ (æ”¯æŒ .xlsx, .xls, .csv)')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ (é»˜è®¤è‡ªåŠ¨ç”Ÿæˆ)', default=None)
    parser.add_argument('--min-click', type=int, default=10,
                       help='æœ€å°ç‚¹å‡»é‡é˜ˆå€¼ï¼Œç”¨äºè¿‡æ»¤é•¿å°¾æ•°æ® (é»˜è®¤: 10)')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.file).exists():
        print(f"âœ— é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {args.file}")
        sys.exit(1)

    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
    analyzer = FunnelAnalyzer(args.file, min_click_threshold=args.min_click)
    success = analyzer.run_analysis(args.output)

    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
